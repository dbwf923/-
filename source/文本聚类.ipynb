{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 载入所需库包\n",
    "import datetime\n",
    "import collections\n",
    "import jieba\n",
    "import re\n",
    "from sklearn.cluster import KMeans,MiniBatchKMeans\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import metrics\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning, DataConversionWarning, FitFailedWarning, NotFittedError\n",
    "# 忽略所有的警告\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.读入 分词后的新闻标题、网址及文本 的 Excel档\n",
      "开始时间：2024-12-20 19:34:43.251315\n",
      "\n",
      "{'于是': 55226, '孤独患者': 56084, '罗生门': 53871}\n",
      "聚类数据数量：165181，异常数据数量：0，结束时间：2024-12-20 19:34:55.396408\n",
      "\n",
      "结束时间：2024-12-20 19:34:55.413179\n"
     ]
    }
   ],
   "source": [
    "#1.读入 分词后的新闻标题、网址及文本 的 Excel档\n",
    "print ('1.读入 分词后的新闻标题、网址及文本 的 Excel档' )\n",
    "print('开始时间：' + str(datetime.datetime.now()))\n",
    "\n",
    "news_df = pd.read_excel('data分词后.xlsx', header=0)\n",
    "\n",
    "# 检查训练数据是否合规\n",
    "categories = {'于是':0, '孤独患者':0, '罗生门':0}\n",
    "i = 0; err = 0\n",
    "while i < len(news_df):\n",
    "    if len(str(news_df.分词后内容[i])) < 1: err = err + 1 # 文本少于10个字视为异常\n",
    "    categories[news_df.歌名[i]] += 1 # 累计各类文本数量\n",
    "    i = i + 1\n",
    "\n",
    "# 打印出 各类训练数量、总数量 及 异常数量\n",
    "print('')\n",
    "print(categories) \n",
    "print('聚类数据数量：' + str(len(news_df)) + '，异常数据数量：' + str(err) \n",
    "      + '，结束时间：' + str(datetime.datetime.now()))\n",
    "\n",
    "# print(news_df[:5])\n",
    "\n",
    "news_df['聚类'] = ''\n",
    "news_df['聚类用内容'] = ''\n",
    "\n",
    "print('\\n结束时间：' + str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.抽取词向量特征\n",
      "开始时间：2024-12-20 19:34:55.420170\n",
      "tfidf.shape：(165181, 10000)\n",
      "len(word)：10000\n",
      "tfidf.shape：(165181, 10000)\n",
      "len(word)：10000\n",
      "len(weight)：165181\n",
      "\n",
      "结束时间：2024-12-20 19:34:56.918477\n"
     ]
    }
   ],
   "source": [
    "#2.抽取词向量特征\n",
    "print ('2.抽取词向量特征' )\n",
    "print('开始时间：' + str(datetime.datetime.now()))\n",
    "\n",
    "docs = news_df['分词后内容'].tolist()  # 更简洁的列表推导式\n",
    "\n",
    "# 设置特征数量限制\n",
    "max_features = 10000  # 根据您的内存调整\n",
    "vectorizer = TfidfVectorizer(max_df=0.7, max_features=max_features)\n",
    "tfidf = vectorizer.fit_transform(docs)\n",
    " \n",
    "word = vectorizer.get_feature_names_out()\n",
    "\n",
    "print('tfidf.shape：' + str(tfidf.shape))\n",
    "print('len(word)：' + str(len(word)))\n",
    "\n",
    "weight = tfidf.toarray()       # 将 tf-idf 矩阵抽取出来\n",
    "#元素w[i][j]表示j词在i类文本的 tf-idf 权重\n",
    "\n",
    "print('tfidf.shape：' + str(tfidf.shape))\n",
    "print('len(word)：' + str(len(word)))\n",
    "print('len(weight)：' + str(len(weight)))\n",
    "\n",
    "print('\\n结束时间：' + str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.设置聚类个数\n",
      "开始时间：2024-12-20 19:34:56.936147\n",
      "前十笔文本聚类结果：\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "\n",
      "结束时间：2024-12-20 19:45:51.453507\n"
     ]
    }
   ],
   "source": [
    "# 3.设置聚类个数，为了兼顾可解释性、有效性，可通过不同 k 值进行迭代比较\n",
    "print ('3.设置聚类个数' )\n",
    "print('开始时间：' + str(datetime.datetime.now()))\n",
    "\n",
    "k = 3\n",
    "kmeans = KMeans(n_clusters=k)\n",
    "#kmini_model = kmini.fit(weight)\n",
    "pca = PCA(n_components=1000)\n",
    "newData = pca.fit_transform(weight)\n",
    "kmeans.fit(weight)\n",
    "\n",
    "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
    "n_clusters=k, n_init=100, random_state=None, tol=0.001, verbose=0)\n",
    "print('前十笔文本聚类结果：')\n",
    "print(kmeans.labels_[:10])\n",
    "\n",
    "print('\\n结束时间：' + str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.各聚类的文本数量及常用词汇\n",
      "开始时间：2024-12-20 19:45:51.543354\n",
      "cluster[0]：6245 条评论，用词总数 及 词频前20名：\n",
      "261\n",
      "[('加油', 6628), ('兄弟', 104), ('宝宝', 85), ('大笑', 83), ('可怜', 45), ('成功', 45), ('陌生人', 42), ('可爱', 40), ('中考', 26), ('比耶', 22), ('高考', 21), ('憨笑', 20), ('天天开心', 15), ('好好', 15), ('努力', 15), ('考上', 13), ('耍酷', 11), ('越来越', 10), ('爱心', 10), ('上岸', 9)]\n",
      " \n",
      "cluster[1]：3665 条评论，用词总数 及 词频前20名：\n",
      "2759\n",
      "[('希望', 3965), ('幸福', 423), ('开心', 304), ('好好', 248), ('永远', 219), ('可怜', 208), ('天天开心', 195), ('下次', 181), ('喜欢', 178), ('大笑', 175), ('大哭', 163), ('生活', 158), ('难过', 145), ('有人', 131), ('快乐', 128), ('身边', 125), ('真的', 121), ('加油', 103), ('明年', 94), ('遇见', 91)]\n",
      " \n",
      "cluster[2]：155271 条评论，用词总数 及 词频前20名：\n",
      "39644\n",
      "[('喜欢', 13813), ('幸福', 11274), ('真的', 6556), ('永远', 6524), ('大哭', 4567), ('流泪', 4415), ('世界', 3889), ('朋友', 3757), ('开心', 3581), ('难过', 3532), ('好好', 3409), ('冬天', 3394), ('生活', 3298), ('眼泪', 3121), ('不想', 3095), ('好像', 3089), ('我爱你', 3029), ('回忆', 2978), ('时间', 2909), ('大笑', 2716)]\n",
      " \n",
      "结束时间：2024-12-20 19:46:04.458463\n"
     ]
    }
   ],
   "source": [
    "# 4.各聚类的文本数量及常用词汇\n",
    "print ('4.各聚类的文本数量及常用词汇' )\n",
    "print('开始时间：' + str(datetime.datetime.now()))\n",
    "\n",
    "cluster = [[], [], []]\n",
    "for i in range(len(kmeans.labels_)):\n",
    "    if kmeans.labels_[i]==0:\n",
    "        cluster[0].append(docs[i])\n",
    "    if kmeans.labels_[i]==1:\n",
    "        cluster[1].append(docs[i])\n",
    "    if kmeans.labels_[i]==2:\n",
    "        cluster[2].append(docs[i])\n",
    "    if kmeans.labels_[i]==3:\n",
    "        cluster[3].append(docs[i])\n",
    "    news_df.loc[i, '聚类'] = str(kmeans.labels_[i])\n",
    "    news_df.loc[i, '聚类用内容'] = docs[i]\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "for i in range(3):\n",
    "    print('cluster[' + str(i) + ']：' + str(len(cluster[i])) + ' 条评论，用词总数 及 词频前20名：')\n",
    "    clustercontent = ' '.join(cluster[i])\n",
    "#    print('clustercontent：' + str(len(clustercontent)))\n",
    "    words = clustercontent.split()\n",
    "#    print('words：' + str(len(words)))\n",
    "    \n",
    "    #取词频前20名的字词(改采 collections 库)\n",
    "    word_freq = Counter(words)\n",
    "    print(len(word_freq))\n",
    "    print(word_freq.most_common(20))  \n",
    "    print(' ')\n",
    "    \n",
    "print('结束时间：' + str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.将聚类后的 新闻 DataFrame 存入 Excel 档\n",
      "开始时间：2024-12-20 19:46:04.477147\n",
      "\n",
      "结束时间：2024-12-20 19:46:25.985380\n"
     ]
    }
   ],
   "source": [
    "# 5.将聚类后的 新闻 DataFrame 存入 Excel 档\n",
    "print ('5.将聚类后的 新闻 DataFrame 存入 Excel 档' )\n",
    "print('开始时间：' + str(datetime.datetime.now()))\n",
    "\n",
    "news_df.to_excel('data聚类后.xlsx', header=True)\n",
    "\n",
    "print('\\n结束时间：' + str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.将聚类后的结果作成交叉分析表\n",
      "开始时间：2024-12-20 19:46:25.993139\n",
      " \n",
      "聚类       0     1       2      合计\n",
      "歌名                              \n",
      "于是     737  1315   53174   55226\n",
      "孤独患者  1751  1205   53128   56084\n",
      "罗生门   3757  1145   48969   53871\n",
      "合计    6245  3665  155271  165181\n",
      "\n",
      "结束时间：2024-12-20 19:46:26.089978\n"
     ]
    }
   ],
   "source": [
    "# 6.将聚类后的结果作成交叉分析表\n",
    "print ('6.将聚类后的结果作成交叉分析表' )\n",
    "print('开始时间：' + str(datetime.datetime.now()))\n",
    "print(' ')\n",
    "\n",
    "print(pd.crosstab(news_df['歌名'], news_df['聚类'], margins=True, margins_name='合计'))\n",
    "\n",
    "print('\\n结束时间：' + str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
