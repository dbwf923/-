{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning,\n",
    "                        message=\"'multi_class' was deprecated\")\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning,\n",
    "                        message=\"The SAMME.R algorithm .* is deprecated\")\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from sklearn.utils import Bunch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "导入训练数据2024-12-24 10:33:21.533656\n",
      "{'主题1': 36736, '主题2': 29553, '主题3': 29445, '主题4': 32538, '主题5': 34404}\n",
      "训练数据数量：162676，异常数据数量：0，结束时间：2024-12-24 10:33:29.185294\n",
      "\n",
      "导入评估数据2024-12-24 10:33:29.185294\n",
      "{'主题1': 501, '主题2': 501, '主题3': 501, '主题4': 501, '主题5': 501}\n",
      "评估数据数量：2505，异常数据数量：0，结束时间：2024-12-24 10:33:29.325902\n"
     ]
    }
   ],
   "source": [
    "# 导入训练数据\n",
    "print('导入训练数据' + str(datetime.datetime.now()))\n",
    "\n",
    "train_df = pd.read_excel('主题分类训练集.xlsx', header=0)\n",
    "dataset_train = Bunch(target=train_df.主题名, target_names=train_df.主题名, data=train_df.分词后内容)\n",
    "\n",
    "# 检查训练数据是否合规\n",
    "categories = {'主题1':0, '主题2':0, '主题3':0, '主题4':0, '主题5':0}\n",
    "i = 0; err = 0\n",
    "while i < len(dataset_train.data):\n",
    "    if len(str(dataset_train.data[i])) < 1: err = err + 1 # 文本少于1个字视为异常\n",
    "    categories[dataset_train.target[i]] += 1 # 累计各类文本数量\n",
    "    i = i + 1\n",
    "\n",
    "# 打印出 各类训练数量、总数量 及 异常数量\n",
    "print(categories) \n",
    "print('训练数据数量：' + str(len(dataset_train.data)) + '，异常数据数量：' + str(err) \n",
    "      + '，结束时间：' + str(datetime.datetime.now()))\n",
    "print('')\n",
    "\n",
    "# 导入评估数据\n",
    "print('导入评估数据' + str(datetime.datetime.now()))\n",
    "\n",
    "test_df = pd.read_excel('主题分类测试集.xlsx', header=0)\n",
    "dataset_test = Bunch(target=test_df.主题名, target_names=test_df.主题名, data=test_df.分词后内容)\n",
    "\n",
    "# 检查评估数据是否合规\n",
    "categories = {'主题1':0, '主题2':0, '主题3':0, '主题4':0, '主题5':0}\n",
    "i = 0; err = 0\n",
    "while i < len(dataset_test.data):\n",
    "    if len(str(dataset_test.data[i])) < 1: err = err + 1 # 文本少于10个字视为异常\n",
    "    categories[dataset_test.target[i]] += 1 # 累计各类文本数量\n",
    "    i = i + 1\n",
    "\n",
    "# 打印出 各类评估数量、总数量 及 异常数量\n",
    "print(categories) \n",
    "\n",
    "print('评估数据数量：' + str(len(dataset_test.data)) + '，异常数据数量：' + str(err) \n",
    "      + '，结束时间：' + str(datetime.datetime.now()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始时间：2024-12-24 10:33:29.333939\n",
      "计算词频2024-12-24 10:33:29.333939\n",
      "(162676, 39698)\n",
      "结束时间：2024-12-24 10:33:30.593467\n",
      " \n",
      "计算TF-IDF2024-12-24 10:33:30.593467\n",
      "(162676, 39698)\n",
      "\n",
      "结束时间：2024-12-24 10:33:31.645082\n"
     ]
    }
   ],
   "source": [
    "# 2.数据准备与理解\n",
    "print('开始时间：' + str(datetime.datetime.now()))\n",
    "\n",
    "# 计算词频\n",
    "print('计算词频' + str(datetime.datetime.now()))\n",
    "count_vect = CountVectorizer(stop_words='english', decode_error='ignore')\n",
    "X_train_counts = count_vect.fit_transform(dataset_train.data)\n",
    "\n",
    "# 查看数据维度\n",
    "print(X_train_counts.shape)\n",
    "print('结束时间：' + str(datetime.datetime.now()))\n",
    "print(' ')\n",
    "\n",
    "# 计算TF-IDF：词频 x 逆文本频率 = (特定词语的词频/文件长度) x log(总文档数/含有特定词的文档数)\n",
    "print('计算TF-IDF' + str(datetime.datetime.now()))\n",
    "tf_transformer = TfidfVectorizer(stop_words='english', decode_error='ignore')\n",
    "X_train_counts_tf = tf_transformer.fit_transform(dataset_train.data)\n",
    "# 查看数据维度\n",
    "print(X_train_counts_tf.shape)\n",
    "\n",
    "print('\\n结束时间：' + str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始时间：2024-12-24 10:33:31.653188\n",
      "LR算法2024-12-24 10:33:31.653188\n",
      "LR : 0.912021 (0.002375)，结束时间：2024-12-24 10:35:30.664876\n",
      "CART算法2024-12-24 10:35:30.664876\n",
      "CART : 0.807513 (0.003218)，结束时间：2024-12-24 10:48:02.888457\n",
      "MNB算法2024-12-24 10:48:02.888457\n",
      "MNB : 0.847144 (0.001962)，结束时间：2024-12-24 10:48:06.722548\n",
      "KNN算法2024-12-24 10:48:06.722548\n",
      "KNN : 0.764286 (0.002418)，结束时间：2024-12-24 10:54:32.548042\n",
      "\n",
      "结束时间：2024-12-24 10:54:32.548042\n"
     ]
    }
   ],
   "source": [
    "# 3.评估算法\n",
    "print('开始时间：' + str(datetime.datetime.now()))\n",
    "\n",
    "# 设置评估算法的基准\n",
    "num_folds = 10\n",
    "seed = 7\n",
    "scoring = 'accuracy'\n",
    "\n",
    "# 生成算法模型\n",
    "models = {}\n",
    "models['LR'] = LogisticRegression(solver='lbfgs', multi_class='auto',max_iter=300) # 逻辑回归\n",
    "models['CART'] = DecisionTreeClassifier() # 决策树分类器\n",
    "models['MNB'] = MultinomialNB() # 补素贝叶斯分类器\n",
    "models['KNN'] = KNeighborsClassifier() # K邻近分类器\n",
    "\n",
    "# 比较算法\n",
    "results = []\n",
    "for key in models:\n",
    "    print(key + '算法' + str(datetime.datetime.now()))\n",
    "    kfold = KFold(n_splits=num_folds, random_state=seed, shuffle=True)\n",
    "#    kfold = KFold(n_splits=num_folds)\n",
    "    cv_results = cross_val_score(models[key], X_train_counts_tf, dataset_train.target, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    print('%s : %f (%f)，结束时间：%s' % (key, cv_results.mean(), cv_results.std(), datetime.datetime.now()))\n",
    "    \n",
    "print('\\n结束时间：' + str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始时间：2024-12-24 10:54:32.563065\n",
      "LR 算法调参2024-12-24 10:54:32.563065\n",
      "最优 : 0.9339546331352864 使用 {'C': 200}，结束时间：2024-12-24 11:05:23.785624\n",
      " \n",
      "MNB 算法调参2024-12-24 11:05:23.785624\n",
      "最优 : 0.8484164942143181 使用 {'alpha': 1.5}，结束时间：2024-12-24 11:05:38.177778\n",
      " \n",
      "CART 算法调参2024-12-24 11:05:38.177778\n",
      "最优 : 0.6280582664147583 使用 {'max_depth': 200}，结束时间：2024-12-24 11:27:45.789688\n",
      " \n",
      "KNN 算法调参2024-12-24 11:27:45.789688\n",
      "最优 : 0.7693636755852352 使用 {'n_neighbors': 3}，结束时间：2024-12-24 11:57:20.094119\n"
     ]
    }
   ],
   "source": [
    "# 4.算法调参\n",
    "print('开始时间：' + str(datetime.datetime.now()))\n",
    "\n",
    "# 调参LR\n",
    "param_grid = {}\n",
    "param_grid['C'] = [13, 15, 20, 200] # 逻辑回归的超参数是目标约束函数C\n",
    "\n",
    "print('LR 算法调参' + str(datetime.datetime.now()))\n",
    "model = LogisticRegression(solver='lbfgs', multi_class='auto', max_iter=10000)\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed, shuffle=True)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n",
    "grid_result = grid.fit(X=X_train_counts_tf, y=dataset_train.target)\n",
    "print('最优 : %s 使用 %s，结束时间：%s' % (grid_result.best_score_, grid_result.best_params_, datetime.datetime.now()))\n",
    "print(' ')\n",
    "\n",
    "# 调参MNB\n",
    "param_grid = {}\n",
    "param_grid['alpha'] = [0.001, 0.01, 0.1, 1.5] # 补素贝叶斯是通过alpha调参\n",
    "\n",
    "print('MNB 算法调参' + str(datetime.datetime.now()))\n",
    "model = MultinomialNB()\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed, shuffle=True)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n",
    "grid_result = grid.fit(X=X_train_counts_tf, y=dataset_train.target)\n",
    "print('最优 : %s 使用 %s，结束时间：%s' % (grid_result.best_score_, grid_result.best_params_, datetime.datetime.now()))\n",
    "print(' ')\n",
    "\n",
    "# 调参CART\n",
    "param_grid = {}\n",
    "param_grid['max_depth'] = [90, 100, 120, 150, 200] # 决策树是通过 最大深度 调参\n",
    "\n",
    "print('CART 算法调参' + str(datetime.datetime.now()))\n",
    "model = DecisionTreeClassifier(criterion = 'gini') # 决策树分类器\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed, shuffle=True)\n",
    "#kfold = KFold(n_splits=num_folds)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n",
    "grid_result = grid.fit(X=X_train_counts_tf, y=dataset_train.target)\n",
    "print('最优 : %s 使用 %s，结束时间：%s' % (grid_result.best_score_, grid_result.best_params_, datetime.datetime.now()))\n",
    "print(' ')\n",
    "\n",
    "# 调参KNN\n",
    "param_grid = {}\n",
    "param_grid['n_neighbors'] = [3, 5, 7, 9, 11] # K邻近是通过 邻近数(k) 调参\n",
    "\n",
    "print('KNN 算法调参' + str(datetime.datetime.now()))\n",
    "model = KNeighborsClassifier() # K邻近分类器\n",
    "\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed, shuffle=True)\n",
    "#kfold = KFold(n_splits=num_folds)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n",
    "grid_result = grid.fit(X=X_train_counts_tf, y=dataset_train.target)\n",
    "print('最优 : %s 使用 %s，结束时间：%s' % (grid_result.best_score_, grid_result.best_params_, datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始时间：2024-12-24 13:51:48.208469\n",
      "准确率：0.9297405189620759\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         主题1       0.92      0.94      0.93       501\n",
      "         主题2       0.93      0.91      0.92       501\n",
      "         主题3       0.94      0.94      0.94       501\n",
      "         主题4       0.95      0.94      0.94       501\n",
      "         主题5       0.91      0.93      0.92       501\n",
      "\n",
      "    accuracy                           0.93      2505\n",
      "   macro avg       0.93      0.93      0.93      2505\n",
      "weighted avg       0.93      0.93      0.93      2505\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('开始时间：'+str(datetime.datetime.now()))\n",
    "\n",
    "model = LogisticRegression(solver='lbfgs', multi_class='auto', max_iter=10000, C = 200)\n",
    "# model = MultinomialNB(alpha = 0.01)\n",
    "model.fit(X_train_counts_tf, dataset_train.target) # 训练模型\n",
    "X_test_counts = tf_transformer.transform(dataset_test.data) # 评估数据集\n",
    "predictions = model.predict(X_test_counts) # 预测\n",
    "print('准确率：' + str(accuracy_score(dataset_test.target, predictions)))\n",
    "print(classification_report(dataset_test.target, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
