{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning,\n",
    "                        message=\"'multi_class' was deprecated\")\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning,\n",
    "                        message=\"The SAMME.R algorithm .* is deprecated\")\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from sklearn.utils import Bunch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入训练数据\n",
    "print('导入训练数据' + str(datetime.datetime.now()))\n",
    "\n",
    "train_df = pd.read_excel('分类训练集.xlsx', header=0)\n",
    "dataset_train = Bunch(target=train_df.歌名, target_names=train_df.歌名, data=train_df.分词后内容)\n",
    "\n",
    "# 检查训练数据是否合规\n",
    "categories = {'于是':0, '孤独患者':0, '罗生门':0}\n",
    "i = 0; err = 0\n",
    "while i < len(dataset_train.data):\n",
    "    if len(str(dataset_train.data[i])) < 1: err = err + 1 # 文本少于1个字视为异常\n",
    "    categories[dataset_train.target[i]] += 1 # 累计各类文本数量\n",
    "    i = i + 1\n",
    "\n",
    "# 打印出 各类训练数量、总数量 及 异常数量\n",
    "print(categories) \n",
    "print('训练数据数量：' + str(len(dataset_train.data)) + '，异常数据数量：' + str(err) \n",
    "      + '，结束时间：' + str(datetime.datetime.now()))\n",
    "print('')\n",
    "\n",
    "# 导入评估数据\n",
    "print('导入评估数据' + str(datetime.datetime.now()))\n",
    "\n",
    "test_df = pd.read_excel('分类测试集.xlsx', header=0)\n",
    "dataset_test = Bunch(target=test_df.歌名, target_names=test_df.歌名, data=test_df.分词后内容)\n",
    "\n",
    "# 检查评估数据是否合规\n",
    "categories = {'于是':0, '孤独患者':0, '罗生门':0}\n",
    "i = 0; err = 0\n",
    "while i < len(dataset_test.data):\n",
    "    if len(str(dataset_test.data[i])) < 10: err = err + 1 # 文本少于10个字视为异常\n",
    "    categories[dataset_test.target[i]] += 1 # 累计各类文本数量\n",
    "    i = i + 1\n",
    "\n",
    "# 打印出 各类评估数量、总数量 及 异常数量\n",
    "print(categories) \n",
    "\n",
    "print('评估数据数量：' + str(len(dataset_test.data)) + '，异常数据数量：' + str(err) \n",
    "      + '，结束时间：' + str(datetime.datetime.now()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.数据准备与理解\n",
    "print('开始时间：' + str(datetime.datetime.now()))\n",
    "\n",
    "# 计算词频\n",
    "print('计算词频' + str(datetime.datetime.now()))\n",
    "count_vect = CountVectorizer(stop_words='english', decode_error='ignore')\n",
    "X_train_counts = count_vect.fit_transform(dataset_train.data)\n",
    "\n",
    "# 查看数据维度\n",
    "print(X_train_counts.shape)\n",
    "print('结束时间：' + str(datetime.datetime.now()))\n",
    "print(' ')\n",
    "\n",
    "# 计算TF-IDF：词频 x 逆文本频率 = (特定词语的词频/文件长度) x log(总文档数/含有特定词的文档数)\n",
    "print('计算TF-IDF' + str(datetime.datetime.now()))\n",
    "tf_transformer = TfidfVectorizer(stop_words='english', decode_error='ignore')\n",
    "X_train_counts_tf = tf_transformer.fit_transform(dataset_train.data)\n",
    "# 查看数据维度\n",
    "print(X_train_counts_tf.shape)\n",
    "\n",
    "print('\\n结束时间：' + str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.评估算法\n",
    "print('开始时间：' + str(datetime.datetime.now()))\n",
    "\n",
    "# 设置评估算法的基准\n",
    "num_folds = 10\n",
    "seed = 7\n",
    "scoring = 'accuracy'\n",
    "\n",
    "# 生成算法模型\n",
    "models = {}\n",
    "models['LR'] = LogisticRegression(solver='lbfgs', multi_class='auto',max_iter=300) # 逻辑回归\n",
    "models['CART'] = DecisionTreeClassifier() # 决策树分类器\n",
    "models['MNB'] = MultinomialNB() # 补素贝叶斯分类器\n",
    "models['KNN'] = KNeighborsClassifier() # K邻近分类器\n",
    "\n",
    "# 比较算法\n",
    "results = []\n",
    "for key in models:\n",
    "    print(key + '算法' + str(datetime.datetime.now()))\n",
    "    kfold = KFold(n_splits=num_folds, random_state=seed, shuffle=True)\n",
    "#    kfold = KFold(n_splits=num_folds)\n",
    "    cv_results = cross_val_score(models[key], X_train_counts_tf, dataset_train.target, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    print('%s : %f (%f)，结束时间：%s' % (key, cv_results.mean(), cv_results.std(), datetime.datetime.now()))\n",
    "    \n",
    "print('\\n结束时间：' + str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.算法调参\n",
    "print('开始时间：' + str(datetime.datetime.now()))\n",
    "\n",
    "# 调参LR\n",
    "param_grid = {}\n",
    "param_grid['C'] = [13, 15, 20, 200] # 逻辑回归的超参数是目标约束函数C\n",
    "\n",
    "print('LR 算法调参' + str(datetime.datetime.now()))\n",
    "model = LogisticRegression(solver='lbfgs', multi_class='auto', max_iter=10000)\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed, shuffle=True)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n",
    "grid_result = grid.fit(X=X_train_counts_tf, y=dataset_train.target)\n",
    "print('最优 : %s 使用 %s，结束时间：%s' % (grid_result.best_score_, grid_result.best_params_, datetime.datetime.now()))\n",
    "print(' ')\n",
    "\n",
    "# 调参MNB\n",
    "param_grid = {}\n",
    "param_grid['alpha'] = [0.001, 0.01, 0.1, 1.5] # 补素贝叶斯是通过alpha调参\n",
    "\n",
    "print('MNB 算法调参' + str(datetime.datetime.now()))\n",
    "model = MultinomialNB()\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed, shuffle=True)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n",
    "grid_result = grid.fit(X=X_train_counts_tf, y=dataset_train.target)\n",
    "print('最优 : %s 使用 %s，结束时间：%s' % (grid_result.best_score_, grid_result.best_params_, datetime.datetime.now()))\n",
    "print(' ')\n",
    "\n",
    "# 调参CART\n",
    "param_grid = {}\n",
    "param_grid['max_depth'] = [90, 100, 120, 150, 200] # 决策树是通过 最大深度 调参\n",
    "\n",
    "print('CART 算法调参' + str(datetime.datetime.now()))\n",
    "model = DecisionTreeClassifier(criterion = 'gini') # 决策树分类器\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed, shuffle=True)\n",
    "#kfold = KFold(n_splits=num_folds)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n",
    "grid_result = grid.fit(X=X_train_counts_tf, y=dataset_train.target)\n",
    "print('最优 : %s 使用 %s，结束时间：%s' % (grid_result.best_score_, grid_result.best_params_, datetime.datetime.now()))\n",
    "print(' ')\n",
    "\n",
    "# 调参KNN\n",
    "param_grid = {}\n",
    "param_grid['n_neighbors'] = [3, 5, 7, 9, 11] # K邻近是通过 邻近数(k) 调参\n",
    "\n",
    "print('KNN 算法调参' + str(datetime.datetime.now()))\n",
    "model = KNeighborsClassifier() # K邻近分类器\n",
    "\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed, shuffle=True)\n",
    "#kfold = KFold(n_splits=num_folds)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n",
    "grid_result = grid.fit(X=X_train_counts_tf, y=dataset_train.target)\n",
    "print('最优 : %s 使用 %s，结束时间：%s' % (grid_result.best_score_, grid_result.best_params_, datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "outputs": [],
   "source": [
    "# 6.选择最优算法，生成模型\n",
    "from sklearn.metrics import classification_report\n",
    "print ('6.选择最优算法，生成模型')\n",
    "print('算法评估' + str(datetime.datetime.now()))\n",
    "\n",
    "best_mnb = grid_result.best_estimator_\n",
    "X_test_counts = count_vect.transform(dataset_test.data)\n",
    "y_test = dataset_test.target\n",
    "# 进行预测\n",
    "y_pred = best_mnb.predict(X_test_counts) \n",
    "# 计算准确率\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'准确率: {accuracy}')\n",
    "class_report = classification_report(dataset_test.target, y_pred)\n",
    "print('Classification Report:')\n",
    "print(class_report)\n",
    "print('MNB 算法调参结束' + str(datetime.datetime.now()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
