{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning,\n",
    "                        message=\"'multi_class' was deprecated\")\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning,\n",
    "                        message=\"The SAMME.R algorithm .* is deprecated\")\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from sklearn.utils import Bunch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "导入训练数据2024-12-25 07:45:45.397573\n",
      "{'于是': 54725, '孤独患者': 55583, '罗生门': 53368}\n",
      "训练数据数量：163676，异常数据数量：0，结束时间：2024-12-25 07:45:54.179471\n",
      "\n",
      "导入评估数据2024-12-25 07:45:54.179471\n",
      "{'于是': 501, '孤独患者': 501, '罗生门': 503}\n",
      "评估数据数量：1505，异常数据数量：979，结束时间：2024-12-25 07:45:54.289067\n"
     ]
    }
   ],
   "source": [
    "# 导入训练数据\n",
    "print('导入训练数据' + str(datetime.datetime.now()))\n",
    "\n",
    "train_df = pd.read_excel('分类训练集.xlsx', header=0)\n",
    "dataset_train = Bunch(target=train_df.歌名, target_names=train_df.歌名, data=train_df.分词后内容)\n",
    "\n",
    "# 检查训练数据是否合规\n",
    "categories = {'于是':0, '孤独患者':0, '罗生门':0}\n",
    "i = 0; err = 0\n",
    "while i < len(dataset_train.data):\n",
    "    if len(str(dataset_train.data[i])) < 1: err = err + 1 # 文本少于1个字视为异常\n",
    "    categories[dataset_train.target[i]] += 1 # 累计各类文本数量\n",
    "    i = i + 1\n",
    "\n",
    "# 打印出 各类训练数量、总数量 及 异常数量\n",
    "print(categories) \n",
    "print('训练数据数量：' + str(len(dataset_train.data)) + '，异常数据数量：' + str(err) \n",
    "      + '，结束时间：' + str(datetime.datetime.now()))\n",
    "print('')\n",
    "\n",
    "# 导入评估数据\n",
    "print('导入评估数据' + str(datetime.datetime.now()))\n",
    "\n",
    "test_df = pd.read_excel('分类测试集.xlsx', header=0)\n",
    "dataset_test = Bunch(target=test_df.歌名, target_names=test_df.歌名, data=test_df.分词后内容)\n",
    "\n",
    "# 检查评估数据是否合规\n",
    "categories = {'于是':0, '孤独患者':0, '罗生门':0}\n",
    "i = 0; err = 0\n",
    "while i < len(dataset_test.data):\n",
    "    if len(str(dataset_test.data[i])) < 10: err = err + 1 # 文本少于10个字视为异常\n",
    "    categories[dataset_test.target[i]] += 1 # 累计各类文本数量\n",
    "    i = i + 1\n",
    "\n",
    "# 打印出 各类评估数量、总数量 及 异常数量\n",
    "print(categories) \n",
    "\n",
    "print('评估数据数量：' + str(len(dataset_test.data)) + '，异常数据数量：' + str(err) \n",
    "      + '，结束时间：' + str(datetime.datetime.now()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始时间：2024-12-25 07:45:54.302334\n",
      "计算词频2024-12-25 07:45:54.302334\n",
      "(163676, 39814)\n",
      "结束时间：2024-12-25 07:45:55.273144\n",
      " \n",
      "计算TF-IDF2024-12-25 07:45:55.273144\n",
      "(163676, 39814)\n",
      "\n",
      "结束时间：2024-12-25 07:45:56.169882\n"
     ]
    }
   ],
   "source": [
    "# 2.数据准备与理解\n",
    "print('开始时间：' + str(datetime.datetime.now()))\n",
    "\n",
    "# 计算词频\n",
    "print('计算词频' + str(datetime.datetime.now()))\n",
    "count_vect = CountVectorizer(stop_words='english', decode_error='ignore')\n",
    "X_train_counts = count_vect.fit_transform(dataset_train.data)\n",
    "\n",
    "# 查看数据维度\n",
    "print(X_train_counts.shape)\n",
    "print('结束时间：' + str(datetime.datetime.now()))\n",
    "print(' ')\n",
    "\n",
    "# 计算TF-IDF：词频 x 逆文本频率 = (特定词语的词频/文件长度) x log(总文档数/含有特定词的文档数)\n",
    "print('计算TF-IDF' + str(datetime.datetime.now()))\n",
    "tf_transformer = TfidfVectorizer(stop_words='english', decode_error='ignore')\n",
    "X_train_counts_tf = tf_transformer.fit_transform(dataset_train.data)\n",
    "# 查看数据维度\n",
    "print(X_train_counts_tf.shape)\n",
    "\n",
    "print('\\n结束时间：' + str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始时间：2024-12-25 07:45:56.188483\n",
      "LR算法2024-12-25 07:45:56.188483\n",
      "LR : 0.478262 (0.003680)，结束时间：2024-12-25 07:47:36.814708\n",
      "CART算法2024-12-25 07:47:36.814708\n",
      "CART : 0.477737 (0.001955)，结束时间：2024-12-25 08:06:08.761380\n",
      "MNB算法2024-12-25 08:06:08.761380\n",
      "MNB : 0.480712 (0.004684)，结束时间：2024-12-25 08:06:12.421295\n",
      "KNN算法2024-12-25 08:06:12.421295\n",
      "KNN : 0.451196 (0.006087)，结束时间：2024-12-25 08:13:39.511260\n",
      "\n",
      "结束时间：2024-12-25 08:13:39.520478\n"
     ]
    }
   ],
   "source": [
    "# 3.评估算法\n",
    "print('开始时间：' + str(datetime.datetime.now()))\n",
    "\n",
    "# 设置评估算法的基准\n",
    "num_folds = 10\n",
    "seed = 7\n",
    "scoring = 'accuracy'\n",
    "\n",
    "# 生成算法模型\n",
    "models = {}\n",
    "models['LR'] = LogisticRegression(solver='lbfgs', multi_class='auto',max_iter=300) # 逻辑回归\n",
    "models['CART'] = DecisionTreeClassifier() # 决策树分类器\n",
    "models['MNB'] = MultinomialNB() # 补素贝叶斯分类器\n",
    "models['KNN'] = KNeighborsClassifier() # K邻近分类器\n",
    "\n",
    "# 比较算法\n",
    "results = []\n",
    "for key in models:\n",
    "    print(key + '算法' + str(datetime.datetime.now()))\n",
    "    kfold = KFold(n_splits=num_folds, random_state=seed, shuffle=True)\n",
    "#    kfold = KFold(n_splits=num_folds)\n",
    "    cv_results = cross_val_score(models[key], X_train_counts_tf, dataset_train.target, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    print('%s : %f (%f)，结束时间：%s' % (key, cv_results.mean(), cv_results.std(), datetime.datetime.now()))\n",
    "    \n",
    "print('\\n结束时间：' + str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始时间：2024-12-25 08:13:39.556793\n",
      "LR 算法调参2024-12-25 08:13:39.556793\n",
      "最优 : 0.4774921281115393 使用 {'C': 13}，结束时间：2024-12-25 08:33:53.615591\n",
      " \n",
      "MNB 算法调参2024-12-25 08:33:53.615591\n",
      "最优 : 0.48248980936773994 使用 {'alpha': 0.1}，结束时间：2024-12-25 08:34:07.255512\n",
      " \n",
      "CART 算法调参2024-12-25 08:34:07.255512\n",
      "最优 : 0.43678364336817027 使用 {'max_depth': 200}，结束时间：2024-12-25 08:55:45.024351\n",
      " \n",
      "KNN 算法调参2024-12-25 08:55:45.024351\n",
      "最优 : 0.4534752182959285 使用 {'n_neighbors': 9}，结束时间：2024-12-25 09:32:49.410026\n"
     ]
    }
   ],
   "source": [
    "# 4.算法调参\n",
    "print('开始时间：' + str(datetime.datetime.now()))\n",
    "\n",
    "# 调参LR\n",
    "param_grid = {}\n",
    "param_grid['C'] = [13, 15, 20, 200] # 逻辑回归的超参数是目标约束函数C\n",
    "\n",
    "print('LR 算法调参' + str(datetime.datetime.now()))\n",
    "model = LogisticRegression(solver='lbfgs', multi_class='auto', max_iter=10000)\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed, shuffle=True)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n",
    "grid_result = grid.fit(X=X_train_counts_tf, y=dataset_train.target)\n",
    "print('最优 : %s 使用 %s，结束时间：%s' % (grid_result.best_score_, grid_result.best_params_, datetime.datetime.now()))\n",
    "print(' ')\n",
    "\n",
    "# 调参MNB\n",
    "param_grid = {}\n",
    "param_grid['alpha'] = [0.001, 0.01, 0.1, 1.5] # 补素贝叶斯是通过alpha调参\n",
    "\n",
    "print('MNB 算法调参' + str(datetime.datetime.now()))\n",
    "model = MultinomialNB()\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed, shuffle=True)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n",
    "grid_result = grid.fit(X=X_train_counts_tf, y=dataset_train.target)\n",
    "print('最优 : %s 使用 %s，结束时间：%s' % (grid_result.best_score_, grid_result.best_params_, datetime.datetime.now()))\n",
    "print(' ')\n",
    "\n",
    "# 调参CART\n",
    "param_grid = {}\n",
    "param_grid['max_depth'] = [90, 100, 120, 150, 200] # 决策树是通过 最大深度 调参\n",
    "\n",
    "print('CART 算法调参' + str(datetime.datetime.now()))\n",
    "model = DecisionTreeClassifier(criterion = 'gini') # 决策树分类器\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed, shuffle=True)\n",
    "#kfold = KFold(n_splits=num_folds)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n",
    "grid_result = grid.fit(X=X_train_counts_tf, y=dataset_train.target)\n",
    "print('最优 : %s 使用 %s，结束时间：%s' % (grid_result.best_score_, grid_result.best_params_, datetime.datetime.now()))\n",
    "print(' ')\n",
    "\n",
    "# 调参KNN\n",
    "param_grid = {}\n",
    "param_grid['n_neighbors'] = [3, 5, 7, 9, 11] # K邻近是通过 邻近数(k) 调参\n",
    "\n",
    "print('KNN 算法调参' + str(datetime.datetime.now()))\n",
    "model = KNeighborsClassifier() # K邻近分类器\n",
    "\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed, shuffle=True)\n",
    "#kfold = KFold(n_splits=num_folds)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n",
    "grid_result = grid.fit(X=X_train_counts_tf, y=dataset_train.target)\n",
    "print('最优 : %s 使用 %s，结束时间：%s' % (grid_result.best_score_, grid_result.best_params_, datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.选择最优算法，生成模型\n",
      "算法评估2024-12-25 09:33:02.490245\n",
      "准确率: 0.47840531561461797\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          于是       0.46      0.67      0.55       501\n",
      "        孤独患者       0.37      0.25      0.30       501\n",
      "         罗生门       0.58      0.51      0.55       503\n",
      "\n",
      "    accuracy                           0.48      1505\n",
      "   macro avg       0.47      0.48      0.47      1505\n",
      "weighted avg       0.47      0.48      0.47      1505\n",
      "\n",
      "MNB 算法调参结束2024-12-25 09:33:02.548383\n"
     ]
    }
   ],
   "source": [
    "# 6.选择最优算法，生成模型\n",
    "from sklearn.metrics import classification_report\n",
    "print ('6.选择最优算法，生成模型')\n",
    "print('算法评估' + str(datetime.datetime.now()))\n",
    "\n",
    "best_mnb = grid_result.best_estimator_\n",
    "X_test_counts = count_vect.transform(dataset_test.data)\n",
    "y_test = dataset_test.target\n",
    "# 进行预测\n",
    "y_pred = best_mnb.predict(X_test_counts) \n",
    "# 计算准确率\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'准确率: {accuracy}')\n",
    "class_report = classification_report(dataset_test.target, y_pred)\n",
    "print('Classification Report:')\n",
    "print(class_report)\n",
    "print('MNB 算法调参结束' + str(datetime.datetime.now()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
